{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrintManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import init, Fore, Back, Style\n",
    "from datetime import datetime\n",
    "\n",
    "init(autoreset=True)  # Initialize Colorama\n",
    "\n",
    "class PrintManager:\n",
    "    @staticmethod\n",
    "    def section_header(title):\n",
    "        \"\"\"Print section header\"\"\"\n",
    "        print(f\"\\n{Fore.CYAN}{'='*80}\")\n",
    "        print(f\"{Fore.CYAN}== {title}\")\n",
    "        print(f\"{Fore.CYAN}{'='*80}{Style.RESET_ALL}\\n\")\n",
    "\n",
    "    @staticmethod\n",
    "    def subsection(title):\n",
    "        \"\"\"Print subsection title\"\"\"\n",
    "        print(f\"\\n{Fore.BLUE}{'-'*40}\")\n",
    "        print(f\"{Fore.BLUE}-- {title}\")\n",
    "        print(f\"{Fore.BLUE}{'-'*40}{Style.RESET_ALL}\\n\")\n",
    "\n",
    "    @staticmethod\n",
    "    def success(message):\n",
    "        \"\"\"Print success message\"\"\"\n",
    "        print(f\"{Fore.GREEN}✓ {message}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def error(message):\n",
    "        \"\"\"Print error message\"\"\"\n",
    "        print(f\"{Fore.RED}✗ ERROR: {message}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def warning(message):\n",
    "        \"\"\"Print warning message\"\"\"\n",
    "        print(f\"{Fore.YELLOW}⚠ WARNING: {message}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def info(message):\n",
    "        \"\"\"Print info message\"\"\"\n",
    "        print(f\"{Fore.WHITE}ℹ {message}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def security(message, is_safe=True):\n",
    "        \"\"\"Print security message\"\"\"\n",
    "        if is_safe:\n",
    "            print(f\"{Fore.GREEN}🔒 {message}{Style.RESET_ALL}\")\n",
    "        else:\n",
    "            print(f\"{Fore.RED}🔓 {message}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def query_result(result_text):\n",
    "        \"\"\"Print query result\"\"\"\n",
    "        print(f\"{Fore.CYAN}{result_text}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def performance(metrics):\n",
    "        \"\"\"Print performance metrics\"\"\"\n",
    "        print(f\"\\n{Fore.MAGENTA}📊 Performance Metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{Fore.MAGENTA}   {key}: {value}{Style.RESET_ALL}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def timestamp():\n",
    "        \"\"\"Print timestamp\"\"\"\n",
    "        return f\"[{datetime.now().strftime('%H:%M:%S')}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "\n",
    "pm = PrintManager()\n",
    "\n",
    "GOOGLE_API_KEY = \"YOUR API KEY\" \n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "class IntentAnalysisEvent(Event):\n",
    "    intent: str\n",
    "    message: str\n",
    "    \n",
    "class SQLGenerationEvent(Event):\n",
    "    sql_query: str\n",
    "\n",
    "class SQLExecutionEvent(Event):\n",
    "    execution_result: str\n",
    "    execution_time: float\n",
    "    row_count: int\n",
    "\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str\n",
    "    success: bool\n",
    "    \n",
    "\n",
    "    \n",
    "class IntentAnalyzer(Workflow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.llm = Gemini()\n",
    "        Settings.llm = self.llm\n",
    "        \n",
    "        # Defined intent patterns\n",
    "        self.sql_patterns = [\n",
    "            r'(?i)(show|list|find|search|sort)',\n",
    "            r'(?i)(products|stock|price)',\n",
    "            r'(?i)(how many|total|average)',\n",
    "            r'(?i)(sql|query|database)',\n",
    "            r'(?i)(highest|lowest|maximum|minimum)',\n",
    "        ]\n",
    "        \n",
    "        self.chat_patterns = [\n",
    "            r'(?i)(hello|hi|how are you)',\n",
    "            r'(?i)(chat|talk|conversation)',\n",
    "            r'(?i)(what are you doing|who are you)',\n",
    "            r'(?i)(thank you|thanks)',\n",
    "        ]\n",
    "\n",
    "    async def analyze_intent(self, prompt: str) -> tuple[str, str]:\n",
    "        \"\"\"Analyze the purpose of the user's prompt\"\"\"\n",
    "        # Pattern-based preliminary check\n",
    "        if any(re.search(pattern, prompt) for pattern in self.sql_patterns):\n",
    "            return \"sql\", \"SQL query detected\"\n",
    "        if any(re.search(pattern, prompt) for pattern in self.chat_patterns):\n",
    "            return \"chat\", \"Chat intent detected\"\n",
    "            \n",
    "        # Detailed analysis with LLM\n",
    "        analysis_prompt = f\"\"\"\n",
    "        Please analyze the purpose of the following user message:\n",
    "        \"{prompt}\"\n",
    "        \n",
    "        There are only two options:\n",
    "        1. SQL: The user wants to perform a database query\n",
    "        2. CHAT: The user wants to chat\n",
    "        \n",
    "        Only write \"SQL\" or \"CHAT\".\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.acomplete(analysis_prompt)\n",
    "        intent = str(response).strip().upper()\n",
    "        \n",
    "        if intent == \"SQL\":\n",
    "            return \"sql\", \"LLM analysis: SQL query detected\"\n",
    "        return \"chat\", \"LLM analysis: Chat intent detected\"\n",
    "\n",
    "    @step\n",
    "    async def determine_intent(self, ev: StartEvent) -> StopEvent:  \n",
    "        prompt = ev.topic\n",
    "        intent, message = await self.analyze_intent(prompt)\n",
    "        return StopEvent(result={\"intent\": intent, \"message\": message}) \n",
    "\n",
    "\n",
    "class SQLAnalysisAgent(Workflow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.llm = Gemini()\n",
    "        Settings.llm = self.llm\n",
    "        \n",
    "        # Logging settings\n",
    "        log_file = f'logs/sql_agent_{datetime.now().strftime(\"%Y%m%d\")}.log'\n",
    "        os.makedirs('logs', exist_ok=True)\n",
    "        logging.basicConfig(\n",
    "            filename=log_file,\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        \n",
    "        # SQLite connection\n",
    "        db_path = Path('data/database.db')\n",
    "        if not db_path.parent.exists():\n",
    "            db_path.parent.mkdir(parents=True)\n",
    "        self.db_connection = sqlite3.connect(db_path, check_same_thread=False)\n",
    "        self.cursor = self.db_connection.cursor()\n",
    "        \n",
    "        # Safe SQL patterns\n",
    "        self.safe_patterns = {\n",
    "            'SELECT': r'^SELECT\\s+(?:(?:[\\w\\s,.()*]|\\s)+)\\s+FROM\\s+[\\w]+(?:\\s+WHERE\\s+[\\w\\s><=]+)?(?:\\s+ORDER\\s+BY\\s+[\\w\\s,]+)?(?:\\s+LIMIT\\s+\\d+)?$',\n",
    "            'COUNT': r'^SELECT\\s+COUNT\\s*\\(\\s*\\*\\s*\\)\\s+FROM\\s+[\\w]+(?:\\s+WHERE\\s+[\\w\\s><=]+)?$',\n",
    "            'AVG': r'^SELECT\\s+AVG\\s*\\(\\s*[\\w]+\\s*\\)\\s+FROM\\s+[\\w]+(?:\\s+WHERE\\s+[\\w\\s><=]+)?$'\n",
    "        }\n",
    "        \n",
    "        # Dangerous characters and patterns\n",
    "        self.dangerous_patterns = [\n",
    "            r';.*',                    # Multiple queries\n",
    "            r'--.*',                   # SQL comments\n",
    "            r'/\\*.*?\\*/',             # Multiline comments\n",
    "            r'xp_.*',                 # System stored procedures\n",
    "            r'exec.*',                # Execute commands\n",
    "            r'UNION.*',               # UNION attacks\n",
    "            r'DROP.*',                # DROP commands\n",
    "            r'DELETE.*',              # DELETE commands\n",
    "            r'UPDATE.*',              # UPDATE commands\n",
    "            r'ALTER.*',               # ALTER commands\n",
    "            r'TRUNCATE.*',            # TRUNCATE commands\n",
    "            r'INSERT.*',              # INSERT commands\n",
    "            r'GRANT.*',               # GRANT commands\n",
    "            r'REVOKE.*',              # REVOKE commands\n",
    "            r'SYSTEM.*',              # System commands\n",
    "            r'INTO\\s+(?:OUTFILE|DUMPFILE).*', # File operations\n",
    "        ]\n",
    "        \n",
    "        # Allowed tables and columns\n",
    "        self.allowed_tables = {'products'}\n",
    "        self.allowed_columns = {\n",
    "            'products': {'id', 'name', 'price', 'stock'}\n",
    "        }\n",
    "        \n",
    "        # Malicious prompt patterns\n",
    "        self.malicious_prompt_patterns = [\n",
    "            r'(?i)(drop|delete|truncate|alter)\\s+table',  # Dropping/modifying tables\n",
    "            r'(?i)system\\s+command',                      # System commands\n",
    "            r'(?i)(hack|exploit|attack)',                 # Malicious words\n",
    "            r'(?i)(union\\s+select|join\\s+select)',        # SQL injection\n",
    "            r'(?i)(--|;|/\\*|\\*/)',                        # SQL comments and separators\n",
    "            r'(?i)(xp_cmdshell|exec\\s+sp)',               # Stored procedures\n",
    "            r'(?i)(insert\\s+into|update\\s+set)',          # Data modification\n",
    "            r'(?i)password|username|credential',           # Sensitive data\n",
    "            r'(?i)grant|revoke|permission',               # Permission changes\n",
    "            r'(?i)backup|restore|dump',                   # Backup operations\n",
    "        ]\n",
    "        \n",
    "        # Safe prompt patterns\n",
    "        self.safe_prompt_patterns = [\n",
    "            r'(?i)(show|list|find|search|sort)',\n",
    "            r'(?i)(products|stock|price)',\n",
    "            r'(?i)(how many|total|average)',\n",
    "            r'(?i)(highest|lowest|maximum|minimum)',\n",
    "        ]\n",
    "\n",
    "    def analyze_prompt_safety(self, prompt: str) -> tuple[bool, str]:\n",
    "        \"\"\"Analyze the user's prompt and check its safety\"\"\"\n",
    "        if not prompt or not prompt.strip():\n",
    "            return False, \"Empty query\"\n",
    "            \n",
    "        for pattern in self.malicious_prompt_patterns:\n",
    "            if re.search(pattern, prompt):\n",
    "                return False, f\"Malicious content detected: {pattern}\"\n",
    "        \n",
    "        safe_pattern_found = any(re.search(pattern, prompt) for pattern in self.safe_prompt_patterns)\n",
    "        if not safe_pattern_found:\n",
    "            return False, \"Query does not contain safe patterns\"\n",
    "            \n",
    "        if len(prompt) > 500:\n",
    "            return False, \"Query is too long\"\n",
    "            \n",
    "        return True, \"Safe query\"\n",
    "\n",
    "    async def verify_prompt_with_llm(self, prompt: str) -> tuple[bool, str]:\n",
    "        \"\"\"Verify the safety of the prompt using LLM\"\"\"\n",
    "        verification_prompt = f\"\"\"\n",
    "        Please analyze the safety of the following user query:\n",
    "        \"{prompt}\"\n",
    "        \n",
    "        Check the following:\n",
    "        1. Is there an attempt of SQL injection?\n",
    "        2. Does it contain malicious commands?\n",
    "        3. Are there any statements that threaten system security?\n",
    "        4. Is it a query solely for data reading purposes?\n",
    "        \n",
    "        Only write \"SAFE\" or \"UNSAFE\" and briefly state the reason.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.acomplete(verification_prompt)\n",
    "        result = str(response).strip().upper()\n",
    "        \n",
    "        is_safe = result.startswith(\"SAFE\")\n",
    "        message = result.replace(\"SAFE\", \"\").replace(\"UNSAFE\", \"\").strip()\n",
    "        \n",
    "        return is_safe, message\n",
    "\n",
    "    def sanitize_input(self, value: str) -> str:\n",
    "        \"\"\"Sanitize input against SQL injection\"\"\"\n",
    "        if value is None:\n",
    "            return None\n",
    "        return value.replace(\"'\", \"''\").replace(\";\", \"\").replace(\"--\", \"\")\n",
    "\n",
    "    def validate_sql_safety(self, sql_query: str) -> tuple[bool, str]:\n",
    "        \"\"\"Check the safety of the SQL query\"\"\"\n",
    "        if not sql_query:\n",
    "            return False, \"Empty query\"\n",
    "\n",
    "        sql_upper = sql_query.upper()\n",
    "        \n",
    "        if not sql_upper.strip().startswith('SELECT'):\n",
    "            return False, \"Only SELECT queries are allowed\"\n",
    "\n",
    "        for pattern in self.dangerous_patterns:\n",
    "            if re.search(pattern, sql_upper, re.IGNORECASE):\n",
    "                return False, f\"Dangerous pattern detected: {pattern}\"\n",
    "\n",
    "        tables = re.findall(r'FROM\\s+(\\w+)', sql_query, re.IGNORECASE)\n",
    "        for table in tables:\n",
    "            if table.lower() not in self.allowed_tables:\n",
    "                return False, f\"Unauthorized table: {table}\"\n",
    "\n",
    "        for pattern in self.safe_patterns.values():\n",
    "            if re.match(pattern, sql_query, re.IGNORECASE):\n",
    "                return True, \"Safe query\"\n",
    "\n",
    "        return False, \"Query format is not safe\"\n",
    "\n",
    "    def format_results(self, results, description):\n",
    "        \"\"\"Format query results\"\"\"\n",
    "        if not results:\n",
    "            return \"No results found\"\n",
    "            \n",
    "        column_names = [desc[0] for desc in description]\n",
    "        formatted_result = \"\\nQuery Results:\\n\"\n",
    "        formatted_result += \"-\" * 80 + \"\\n\"\n",
    "        formatted_result += \" | \".join(f\"{col:15}\" for col in column_names) + \"\\n\"\n",
    "        formatted_result += \"-\" * 80 + \"\\n\"\n",
    "        \n",
    "        for row in results:\n",
    "            formatted_result += \" | \".join(f\"{str(item):15}\" for item in row) + \"\\n\"\n",
    "        formatted_result += \"-\" * 80 + \"\\n\"\n",
    "        \n",
    "        return formatted_result\n",
    "\n",
    "    def learn_from_history(self, natural_query: str) -> str:\n",
    "        \"\"\"Learn from past queries\"\"\"\n",
    "        self.cursor.execute(\"\"\"\n",
    "            SELECT natural_query, generated_sql, execution_result \n",
    "            FROM query_history \n",
    "            WHERE natural_query LIKE ? \n",
    "            AND execution_result NOT LIKE '%error%'\n",
    "            ORDER BY created_at DESC \n",
    "            LIMIT 1\n",
    "        \"\"\", (f\"%{natural_query}%\",))\n",
    "        \n",
    "        similar_query = self.cursor.fetchone()\n",
    "        if similar_query:\n",
    "            pm.info(f\"\\nSimilar successful query found:\\n{similar_query}\")\n",
    "            return similar_query[1]\n",
    "        return None\n",
    "\n",
    "    def log_error(self, error_msg: str, query: str):\n",
    "        \"\"\"Log security breaches and errors\"\"\"\n",
    "        logging.error(f\"Security Breach - Query: {query}\\nError: {error_msg}\")\n",
    "        try:\n",
    "            self.cursor.execute(\"\"\"\n",
    "                INSERT INTO error_stats (error_type, query, message)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", ('SECURITY_VIOLATION', query, error_msg))\n",
    "            self.db_connection.commit()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Log entry error: {str(e)}\")\n",
    "\n",
    "    @step\n",
    "    async def generate_sql(self, ev: StartEvent) -> SQLGenerationEvent:\n",
    "        pm.section_header(\"SQL Query Generation\")\n",
    "        prompt = ev.topic\n",
    "        \n",
    "        # Security checks\n",
    "        pm.subsection(\"Security Analysis\")\n",
    "        is_safe, message = self.analyze_prompt_safety(prompt)\n",
    "        if not is_safe:\n",
    "            pm.security(f\"Prompt is not safe: {message}\", False)\n",
    "            return SQLGenerationEvent(sql_query=\"SELECT 'Failed security check' as message\")\n",
    "        \n",
    "        is_safe, message = await self.verify_prompt_with_llm(prompt)\n",
    "        if not is_safe:\n",
    "            pm.security(f\"LLM security check failed: {message}\", False)\n",
    "            return SQLGenerationEvent(sql_query=\"SELECT 'LLM security check failed' as message\")\n",
    "        \n",
    "        pm.security(\"Security checks passed\", True)\n",
    "        \n",
    "        # Generate SQL\n",
    "        pm.subsection(\"SQL Generation\")\n",
    "        query = self.sanitize_input(prompt)\n",
    "        \n",
    "        # Get schema information\n",
    "        self.cursor.execute(\"SELECT table_name, columns_info FROM tables_info\")\n",
    "        schema_info = self.cursor.fetchall()\n",
    "        \n",
    "        # Learn from history\n",
    "        learned_sql = self.learn_from_history(query)\n",
    "        if learned_sql:\n",
    "            pm.info(f\"SQL learned from history: {learned_sql}\")\n",
    "            is_safe, message = self.validate_sql_safety(learned_sql)\n",
    "            if not is_safe:\n",
    "                learned_sql = None\n",
    "                pm.warning(f\"Learned query is not safe: {message}\")\n",
    "        \n",
    "        # Generate SQL with LLM\n",
    "        sql_prompt = f\"\"\"\n",
    "        Database schema:\n",
    "        {schema_info}\n",
    "        \n",
    "        Please translate the following natural language query into an SQL query:\n",
    "        {query}\n",
    "        \n",
    "        IMPORTANT RULES:\n",
    "        1. Only SELECT queries are allowed\n",
    "        2. Only access the 'products' table\n",
    "        3. Allowed columns: id, name, price, stock\n",
    "        4. No multiple queries, comments, or special characters\n",
    "        5. No complex queries like UNION, JOIN\n",
    "        \n",
    "        Only return the SQL query.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.acomplete(sql_prompt)\n",
    "        sql_query = str(response).strip().replace('```sql', '').replace('```', '').strip()\n",
    "        \n",
    "        # Validate SQL query\n",
    "        is_safe, message = self.validate_sql_safety(sql_query)\n",
    "        if not is_safe:\n",
    "            pm.security(f\"Generated SQL is not safe: {message}\", False)\n",
    "            return SQLGenerationEvent(sql_query=\"SELECT 'Security breach detected' as message\")\n",
    "        \n",
    "        pm.success(\"SQL query generated successfully\")\n",
    "        pm.info(f\"Original Query: {query}\")\n",
    "        pm.info(f\"Generated SQL: {sql_query}\")\n",
    "        \n",
    "        # Save SQL query\n",
    "        self.cursor.execute(\n",
    "            \"INSERT INTO query_history (natural_query, generated_sql) VALUES (?, ?)\",\n",
    "            (query, sql_query)\n",
    "        )\n",
    "        self.db_connection.commit()\n",
    "        \n",
    "        return SQLGenerationEvent(sql_query=sql_query)\n",
    "\n",
    "    @step\n",
    "    async def execute_sql(self, ev: SQLGenerationEvent) -> SQLExecutionEvent:\n",
    "        pm.section_header(\"Executing SQL Query\")\n",
    "        sql_query = ev.sql_query\n",
    "        \n",
    "        try:\n",
    "            # Query plan\n",
    "            pm.subsection(\"Query Plan Analysis\")\n",
    "            self.cursor.execute(\"EXPLAIN QUERY PLAN \" + sql_query)\n",
    "            query_plan = self.cursor.fetchall()\n",
    "            for step in query_plan:\n",
    "                pm.info(f\"Plan Step: {step}\")\n",
    "            \n",
    "            # Execute query\n",
    "            pm.subsection(\"Executing Query\")\n",
    "            start_time = time.time()\n",
    "            self.cursor.execute(sql_query)\n",
    "            result = self.cursor.fetchall()\n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            # Format results\n",
    "            formatted_result = self.format_results(result, self.cursor.description)\n",
    "            pm.query_result(formatted_result)\n",
    "            \n",
    "            # Performance metrics\n",
    "            metrics = {\n",
    "                \"Execution Time\": f\"{execution_time:.4f} seconds\",\n",
    "                \"Rows Returned\": len(result),\n",
    "                \"Average Processing Time\": f\"{(execution_time/len(result) if len(result) > 0 else 0):.6f} seconds\"\n",
    "            }\n",
    "            pm.performance(metrics)\n",
    "            \n",
    "            return SQLExecutionEvent(\n",
    "                execution_result=formatted_result,\n",
    "                execution_time=execution_time,\n",
    "                row_count=len(result)\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_message = f\"Error executing SQL query: {str(e)}\"\n",
    "            pm.error(error_message)\n",
    "            self.log_error(str(e), sql_query)\n",
    "            return SQLExecutionEvent(\n",
    "                execution_result=error_message,\n",
    "                execution_time=0,\n",
    "                row_count=0\n",
    "            )\n",
    "\n",
    "    def create_feedback_prompt(self, ev: SQLExecutionEvent) -> str:\n",
    "        \"\"\"Create a feedback prompt for the LLM\"\"\"\n",
    "        return f\"\"\"\n",
    "        Please briefly evaluate the result of this query:\n",
    "        \n",
    "        Query Metrics:\n",
    "        - Execution Time: {ev.execution_time:.4f} seconds\n",
    "        - Rows Returned: {ev.row_count}\n",
    "        \n",
    "        Query Result:\n",
    "        {ev.execution_result}\n",
    "        \n",
    "        Please provide a SHORT and CLEAR evaluation based on the following criteria:\n",
    "        1. Was the query successful? (Yes/No)\n",
    "        2. Is the performance adequate? (Yes/No)\n",
    "        3. If any, what are the improvement suggestions?\n",
    "        \"\"\"\n",
    "\n",
    "    @step\n",
    "    async def collect_feedback(self, ev: SQLExecutionEvent) -> StopEvent:\n",
    "        pm.section_header(\"Query Evaluation\")\n",
    "        \n",
    "        feedback = await self.llm.acomplete(self.create_feedback_prompt(ev))\n",
    "        pm.subsection(\"LLM Evaluation\")\n",
    "        pm.info(str(feedback))\n",
    "         \n",
    "        \n",
    "        return StopEvent(result=str(ev.execution_result))\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Cleanup operations\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'cursor'):\n",
    "                self.cursor.close()\n",
    "            if hasattr(self, 'db_connection'):\n",
    "                self.db_connection.close()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Cleanup error: {str(e)}\")\n",
    "\n",
    "async def run_sql_agent(natural_query: str) -> str:\n",
    "    \"\"\"Run the SQL analysis agent\"\"\"\n",
    "    # First, perform intent analysis\n",
    "    intent_analyzer = IntentAnalyzer()\n",
    "    result_dict = await intent_analyzer.run(topic=natural_query)  # Directly get the dictionary\n",
    "    \n",
    "    if result_dict[\"intent\"] == \"chat\":\n",
    "        pm.warning(\"I am an SQL assistant and can only help with database queries. I am not designed for chatting.\")\n",
    "        return \"Please ask a question related to a database query.\"\n",
    "    \n",
    "    # If it's an SQL query, proceed with the normal flow\n",
    "    agent = SQLAnalysisAgent()\n",
    "    result = await agent.run(topic=natural_query)\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "== SQL Query Generation\n",
      "================================================================================\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "-- Security Analysis\n",
      "----------------------------------------\n",
      "\n",
      "🔒 Security checks passed\n",
      "\n",
      "----------------------------------------\n",
      "-- SQL Generation\n",
      "----------------------------------------\n",
      "\n",
      "✓ SQL query generated successfully\n",
      "ℹ Original Query: Give me the price of the most expensive product\n",
      "ℹ Generated SQL: SELECT MAX(price) FROM products\n",
      "\n",
      "================================================================================\n",
      "== Executing SQL Query\n",
      "================================================================================\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "-- Query Plan Analysis\n",
      "----------------------------------------\n",
      "\n",
      "ℹ Plan Step: (3, 0, 0, 'SEARCH products')\n",
      "\n",
      "----------------------------------------\n",
      "-- Executing Query\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Query Results:\n",
      "--------------------------------------------------------------------------------\n",
      "MAX(price)     \n",
      "--------------------------------------------------------------------------------\n",
      "999.99         \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "📊 Performance Metrics:\n",
      "   Execution Time: 0.0000 seconds\n",
      "   Rows Returned: 1\n",
      "   Average Processing Time: 0.000000 seconds\n",
      "\n",
      "================================================================================\n",
      "== Query Evaluation\n",
      "================================================================================\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "-- LLM Evaluation\n",
      "----------------------------------------\n",
      "\n",
      "ℹ Here's a brief evaluation:\n",
      "\n",
      "1. **Was the query successful?** Yes\n",
      "2. **Is the performance adequate?** Yes\n",
      "3. **Improvement suggestions:**  None needed. The query executed quickly and returned the expected result. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "natural_query = \"Give me the price of the most expensive product\"\n",
    "result = await run_sql_agent(natural_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
